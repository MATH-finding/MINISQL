#!/usr/bin/env python3
"""
索引解析测试文件
"""

import sys
import os

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from sql import SQLLexer, SQLParser
from sql.ast_nodes import CreateIndexStatement, DropIndexStatement


def test_lexer():
    """测试词法分析器"""
    print("=== 测试词法分析器 ===")

    test_sqls = [
        "CREATE INDEX idx_test ON students (id)",
        "CREATE UNIQUE INDEX idx_unique ON students (name)",
        "DROP INDEX idx_test",
    ]

    for sql in test_sqls:
        print(f"\n测试SQL: {sql}")
        try:
            lexer = SQLLexer(sql)
            tokens = lexer.tokenize()

            print("Token序列:")
            for i, token in enumerate(tokens):
                print(f"  [{i}] {token.type.name}: '{token.value}'")

        except Exception as e:
            print(f"词法分析错误: {e}")


def test_parser():
    """测试语法分析器"""
    print("\n=== 测试语法分析器 ===")

    test_cases = [
        {
            "sql": "CREATE INDEX idx_test ON students (id)",
            "expected": "CreateIndexStatement",
        },
        {
            "sql": "CREATE UNIQUE INDEX idx_unique ON students (name)",
            "expected": "CreateIndexStatement(unique=True)",
        },
        {"sql": "DROP INDEX idx_test", "expected": "DropIndexStatement"},
    ]

    for case in test_cases:
        sql = case["sql"]
        print(f"\n测试SQL: {sql}")
        print(f"期望结果: {case['expected']}")

        try:
            lexer = SQLLexer(sql)
            tokens = lexer.tokenize()

            parser = SQLParser(tokens)

            # 添加调试信息
            print(
                f"解析器当前token: {parser.current_token.type.name if parser.current_token else 'None'}"
            )

            ast = parser.parse()

            print(f"实际结果: {type(ast).__name__}")

            if isinstance(ast, CreateIndexStatement):
                print(f"  索引名: {ast.index_name}")
                print(f"  表名: {ast.table_name}")
                print(f"  列名: {ast.column_name}")
                print(f"  唯一索引: {ast.is_unique}")
            elif isinstance(ast, DropIndexStatement):
                print(f"  索引名: {ast.index_name}")

            print("✅ 解析成功")

        except Exception as e:
            print(f"❌ 解析错误: {e}")
            import traceback

            traceback.print_exc()


def test_integration():
    """测试完整流程"""
    print("\n=== 测试完整SQL执行流程 ===")

    try:
        from interface.database import SimpleDatabase

        db = SimpleDatabase("test_index.db")

        # 先创建表
        print("\n1. 创建测试表...")
        result = db.execute_sql(
            "CREATE TABLE test_table (id INTEGER PRIMARY KEY, name VARCHAR(50))"
        )
        print(f"创建表结果: {result}")

        # 尝试创建索引
        print("\n2. 创建索引...")
        result = db.execute_sql("CREATE INDEX idx_test_id ON test_table (id)")
        print(f"创建索引结果: {result}")

        # 尝试创建唯一索引
        print("\n3. 创建唯一索引...")
        result = db.execute_sql(
            "CREATE UNIQUE INDEX idx_test_name ON test_table (name)"
        )
        print(f"创建唯一索引结果: {result}")

        # 查看索引
        print("\n4. 查看索引...")
        indexes = db.list_indexes("test_table")
        print(f"索引列表: {indexes}")

        # 删除索引
        print("\n5. 删除索引...")
        result = db.execute_sql("DROP INDEX idx_test_id")
        print(f"删除索引结果: {result}")

        db.close()

        # 清理测试文件
        if os.path.exists("test_index.db"):
            os.remove("test_index.db")

    except Exception as e:
        print(f"❌ 完整流程测试失败: {e}")
        import traceback

        traceback.print_exc()


def main():
    print("🧪 索引解析测试工具")
    print("=" * 40)

    test_lexer()
    test_parser()
    test_integration()

    print("\n✅ 测试完成")


if __name__ == "__main__":
    main()
